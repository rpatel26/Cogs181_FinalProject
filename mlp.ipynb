{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_file_reader_ops(filename_queue):\n",
    "#    reader = tf.TextLineReader(skip_header_lines=1)\n",
    "#    _, csv_row = reader.read(filename_queue)\n",
    "#    record_defaults = [[0], [0], [0], [0], [0], [0]]\n",
    "#    country, code, gold, silver, bronze, total = tf.decode_csv(csv_row, record_defaults=record_defaults)\n",
    "#    features = tf.pack([gold, silver, bronze])\n",
    "#    return features, country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(label_vec):\n",
    "    if label_vec == \"asian\":\n",
    "       one_hot = 0\n",
    "    elif label_vec == \"country\":\n",
    "       one_hot = 1\n",
    "    elif label_vec == \"pop\":\n",
    "       one_hot = 2\n",
    "    elif label_vec == \"rock\":\n",
    "       one_hot = 3\n",
    "    elif label_vec == \"hip_hop\":\n",
    "       one_hot = 4\n",
    "    else: print \"label not found\"\n",
    "    return one_hot\n",
    "\n",
    "filenames = [\"asian_features.txt\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv(\"asian_features.txt\", comment = \"%\").values\n",
    "with tf.python_io.TFRecordWriter(\"csv.tfrecords\") as tf_writer:\n",
    "    for row in csv:\n",
    "       #file formate : feature 1â€¦..feature n, label\n",
    "       features, label = row[:-1], row[-1]\n",
    "       example = tf.train.Example()\n",
    "       example.features.feature[\"features\"].float_list.value.extend(features)\n",
    "       o_h_labels = one_hot(label)\n",
    "       example.features.feature[\"label\"].int64_list.value.append(o_h_labels)\n",
    "       tf_writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data set somehow\n",
    "#parameters\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "#network parameters\n",
    "n_hidden = 10\n",
    "n_input = 124\n",
    "n_classes = 5\n",
    "\n",
    "#dataset = tf.data.TFRecordDataset(\"csv.tfrecords\")\n",
    "\n",
    "def read_and_decode_single_example(filename):\n",
    "    # first construct a queue containing a list of filenames.\n",
    "    # this lets a user split up there dataset in multiple files to keep\n",
    "    # size down\n",
    "    filename_queue = tf.train.string_input_producer([filename],\n",
    "                                                    num_epochs=None)\n",
    "    # Unlike the TFRecordWriter, the TFRecordReader is symbolic\n",
    "    reader = tf.TFRecordReader()\n",
    "    # One can read a single serialized example from a filename\n",
    "    # serialized_example is a Tensor of type string.\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # The serialized example is converted back to actual values.\n",
    "    # One needs to describe the format of the objects to be returned\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            # We know the length of both fields. If not the\n",
    "            # tf.VarLenFeature could be used\n",
    "            'features': tf.FixedLenFeature([124], tf.float32),\n",
    "            'label': tf.FixedLenFeature([1], tf.int64)\n",
    "        })\n",
    "    # now return the converted data\n",
    "    label = features['label']\n",
    "    feat = features['features']\n",
    "    return label, feat\n",
    "\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'w1': tf.Variable(tf.random_normal([n_input, n_hidden])),\n",
    "    'w2': tf.Variable(tf.random_normal([n_hidden, n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "\n",
    "def mlp(x):\n",
    "   #hidden layer 1\n",
    "   h_layer = tf.matmul(x, weights['w1'])\n",
    "   h_layer_2 = tf.matmul(h_layer, weights['w2']) \n",
    "   out_layer = tf.matmul(h_layer_2, weights['out'])\n",
    "   return out_layer\n",
    "\n",
    "#construct model\n",
    "logits = mlp(X)\n",
    "\n",
    "#define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get single examples\n",
    "label, feat = read_and_decode_single_example(\"csv.tfrecords\")\n",
    "# groups examples into batches randomly\n",
    "labels_batch, feat_batch = tf.train.shuffle_batch(\n",
    "    [label, feat], batch_size=100,\n",
    "    capacity=2000,\n",
    "    min_after_dequeue=1000)\n",
    "\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "   sess.run(init)\n",
    "\n",
    "   #training cycle\n",
    "   train_ac = []\n",
    "   test_ac = []\n",
    "   x_axis = np.arange(1,training_epochs+1)\n",
    "   for epoch in range(training_epochs):\n",
    "      avg_cost = 0.\n",
    "      total_batch = 1\n",
    "      acc = []\n",
    "      # Loop over all batches\n",
    "      for i in range(1):\n",
    "         batch_x, batch_y= sess.run([feat_batch, labels_batch])\n",
    "         # Run optimization op (backprop) and cost op (to get loss value)\n",
    "         _, c = sess.run([train_op, loss_op], feed_dict={X: batch_x, Y: batch_y})\n",
    "#         _, c = sess.run([train_op, loss_op], feed_dict={X: labels_batch, Y: feat_batch})\n",
    "         # Compute average loss\n",
    "         avg_cost += c / total_batch\n",
    "         # Display logs per epoch step\n",
    "        # Display logs per epoch step\n",
    "     ## if epoch % display_step == 0:\n",
    "      print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(avg_cost))\n",
    "      # Test model\n",
    "      pred = tf.nn.softmax(logits)  # Apply softmax to logits\n",
    "      correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "      # Calculate accuracy\n",
    "      accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "      train_ac.append(accuracy.eval({X: feat, Y: labels}))\n",
    "      test_ac.append(accuracy.eval({X: feat, Y: labels}))\n",
    "\n",
    "   print(\"Accuracy of Train\", accuracy.eval({X: feat, Y: labels}))\n",
    "   print(\"Accuracy of Test\", accuracy.eval({X: feat, Y: labels}))\n",
    "    \n",
    "   print(\"Optimization Finished for full MNIST Data Set!\")\n",
    "   plt.plot(x_axis, test_ac)\n",
    "   plt.xlabel(\"Number of Epochs\")\n",
    "   plt.ylabel(\"Test Accuracy\")\n",
    "   plt.show()\n",
    "   plt.plot(x_axis, train_ac)\n",
    "   plt.xlabel(\"Number of Epochs\")\n",
    "   plt.ylabel(\"Training Accuracy\")\n",
    "   plt.show()\n",
    "   print (\"batch_size = 100\")\n",
    "   print (\"learning_rate = 0.001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.train._labels = y_train\n",
    "mnist.train._images = x_train\n",
    "mnist.train._num_examples = 9999\n",
    "\n",
    "with tf.Session() as sess:\n",
    "   sess.run(init)\n",
    "\n",
    "   #training cycle\n",
    "   train_ac = []\n",
    "   test_ac = []\n",
    "   x_axis = np.arange(1,training_epochs+1)\n",
    "   for epoch in range(training_epochs):\n",
    "      avg_cost = 0.\n",
    "      total_batch = int(mnist.train.num_examples/batch_size)\n",
    "      acc = []\n",
    "      # Loop over all batches\n",
    "      for i in range(total_batch):\n",
    "         tf.train.start_queue_runners(sess=sess)\n",
    "         batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "         # Run optimization op (backprop) and cost op (to get loss value)\n",
    "         _, c = sess.run([train_op, loss_op], feed_dict={X: batch_x, Y: batch_y})\n",
    "         # Compute average loss\n",
    "         avg_cost += c / total_batch\n",
    "         # Display logs per epoch step\n",
    "        # Display logs per epoch step\n",
    "      if epoch % display_step == 0:\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(avg_cost))\n",
    "      # Test model\n",
    "      pred = tf.nn.softmax(logits)  # Apply softmax to logits\n",
    "      correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "      # Calculate accuracy\n",
    "      accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "      train_ac.append(accuracy.eval({X: mnist.train.images, Y: mnist.train.labels}))\n",
    "      test_ac.append(accuracy.eval({X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "   print(\"Accuracy of Train\", accuracy.eval({X: mnist.train.images, Y: mnist.train.labels}))\n",
    "   print(\"Accuracy of Test\", accuracy.eval({X: mnist.test.images, Y: mnist.test.labels}))\n",
    "    \n",
    "   print(\"Optimization Finished for small dataset!\")\n",
    "   plt.plot(x_axis, test_ac)\n",
    "   plt.xlabel(\"Number of Epochs\")\n",
    "   plt.ylabel(\"Test Accuracy\")\n",
    "   plt.show()\n",
    "   plt.plot(x_axis, train_ac)\n",
    "   plt.xlabel(\"Number of Epochs\")\n",
    "   plt.ylabel(\"Training Accuracy\")\n",
    "   plt.show()\n",
    "   print (\"batch_size = 100\")\n",
    "   print (\"learning_rate = 0.001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
